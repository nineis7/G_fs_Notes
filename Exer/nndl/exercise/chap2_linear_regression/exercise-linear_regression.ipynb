{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说明\n",
    "\n",
    "请按照填空顺序编号分别完成 参数优化，不同基函数的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data(filename):\n",
    "    \"\"\"载入数据。\"\"\"\n",
    "    xys = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            xys.append(map(float, line.strip().split()))\n",
    "        xs, ys = zip(*xys)\n",
    "        return np.asarray(xs), np.asarray(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同的基函数 (basis function)的实现 填空顺序 2\n",
    "\n",
    "请分别在这里实现“多项式基函数”以及“高斯基函数”\n",
    "\n",
    "其中以及训练集的x的范围在0-25之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([2,1])\n",
    "x = np.expand_dims(x, axis=1) # shape(N, 1)\n",
    "print(x.shape)\n",
    "feat = [x]\n",
    "for i in range(2, 5):\n",
    "    feat.append(x ** i)\n",
    "\n",
    "res = np.concatenate(feat, axis=1)\n",
    "res.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_basis(x):\n",
    "    ret = np.expand_dims(x, axis=1)\n",
    "    return ret\n",
    "\n",
    "def multinomial_basis(x, feature_num=10):\n",
    "    '''多项式基函数'''\n",
    "    x = np.expand_dims(x, axis=1) # shape(N, 1)\n",
    "    #==========\n",
    "    '''多项式基函数即对样本生成不同维度表示'''\n",
    "    #todo '''请实现多项式基函数'''\n",
    "    feat = [x]\n",
    "    for i in range(2, feature_num+1):\n",
    "        feat.append(x**i)\n",
    "    #==========\n",
    "    ret = np.concatenate(feat, axis=1)\n",
    "    return ret\n",
    "\n",
    "def gaussian_basis(x, feature_num=10):\n",
    "    '''高斯基函数'''\n",
    "    #==========\n",
    "    #todo '''请实现高斯基函数'''\n",
    "    #==========\n",
    "    ret = None\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(200,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 程序主入口（建议不要改动以下函数的接口）\n",
    "if __name__ == '__main__':\n",
    "    train_file = 'train.txt'\n",
    "    test_file = 'test.txt'\n",
    "    # 载入数据\n",
    "    x_train, y_train = load_data(train_file)\n",
    "    x_test, y_test = load_data(test_file)\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "\n",
    "x_train[0]\n",
    "w = np.zeros(2)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 返回一个训练好的模型 填空顺序 1 用最小二乘法进行模型优化 \n",
    "## 填空顺序 3 用梯度下降进行模型优化\n",
    "> 先完成最小二乘法的优化 (参考书中第二章 2.3中的公式)\n",
    "\n",
    "> 再完成梯度下降的优化   (参考书中第二章 2.3中的公式)\n",
    "\n",
    "在main中利用训练集训练好模型的参数，并且返回一个训练好的模型。\n",
    "\n",
    "计算出一个优化后的w，请分别使用最小二乘法以及梯度下降两种办法优化w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2,), (2,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2])\n",
    "y = np.expand_dims(np.ones_like(x), axis=1)\n",
    "x = np.array([[4], [5]])\n",
    "z = np.concatenate([x, y], axis=1)\n",
    "z[0].shape, z[1].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(x_train, y_train):\n",
    "    \"\"\"\n",
    "    训练模型，并返回从x到y的映射。\n",
    "    \n",
    "    \"\"\"\n",
    "    basis_func = multinomial_basis\n",
    "    phi0 = np.expand_dims(np.ones_like(x_train), axis=1) #shape(N, 1)\n",
    "    phi1 = basis_func(x_train) #shape(N, basis_expand)\n",
    "    phi = np.concatenate([phi1, phi0], axis=1).T #shape(basis_expand+1, N) 第二行均为1 增广权重向量\n",
    "    \n",
    "    \n",
    "    #==========\n",
    "    #todo '''计算出一个优化后的w，请分别使用最小二乘法以及梯度下降两种办法优化w'''\n",
    "    '''method1 最小二乘'''\n",
    "    # 2xNxNx2x2xNxNx.\n",
    "    w = np.dot(np.dot(np.linalg.inv(np.dot(phi, phi.T)), phi), y_train)\n",
    "    print(\"最小二乘得 w is: \", w)\n",
    "    '''最小二乘法并非如梯度下降般通过训练来求得最优解，而是直接通过数学计算计算出最优解'''\n",
    "    \n",
    "    '''method2 梯度下降'''\n",
    "    training_loop = 1000\n",
    "    learning_rate = 0.001\n",
    "    # def loss_function(x, w, y):\n",
    "    #     std = np.sqrt(np.mean(np.abs(y - np.dot(x, w)) ** 2))\n",
    "    #     return std\n",
    "    \n",
    "    w = np.random.rand(2)\n",
    "    #w = np.expand_dims(w, axis=1)\n",
    "    for j in range(training_loop):\n",
    "        # 2x1 + 2xNxNx1\n",
    "        #w = w + learning_rate * np.dot(phi, (y_train - np.dot(phi.T, w)))\n",
    "        for i in range(len(x_train)):\n",
    "            #print(\"np.dot(phi[i].T, w) shape \", np.dot(phi[i].T, w).shape)\n",
    "            w = w + learning_rate * x_train[i] * (y_train[i] - x_train[i] * w)\n",
    "\n",
    "    print(\"finally w is: \", w)\n",
    "    #==========\n",
    "    \n",
    "    \n",
    "    def f(x):\n",
    "        phi0 = np.expand_dims(np.ones_like(x), axis=1)\n",
    "        phi1 = basis_func(x)\n",
    "        phi = np.concatenate([phi1, phi0], axis=1)\n",
    "        y = np.dot(phi, w) #Nx2x2x1\n",
    "        return y\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.],\n",
       "        [0.]]),\n",
       " (2, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.zeros([2,1])\n",
    "w, w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估结果 \n",
    "> 没有需要填写的代码，但是建议读懂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(200,)\n",
      "最小二乘得 w is:  [ 1.55316310e+01 -1.10841653e+01  3.24580454e+00 -4.40548384e-01\n",
      "  2.35803719e-02  7.68832014e-04 -1.76032302e-04  9.83479732e-06\n",
      " -2.49350536e-07  2.46318602e-09 -2.51244185e+00]\n",
      "finally w is:  [0.92721287 0.92721287]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (300,11) and (2,) not aligned: 11 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33020\\3010935944.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'训练集预测值与真实值的标准差：{:.1f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33020\\2345047852.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mphi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbasis_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mphi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mphi1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Nx2x2x1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda3\\envs\\ML\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (300,11) and (2,) not aligned: 11 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "def evaluate(ys, ys_pred):\n",
    "    \"\"\"评估模型。\"\"\"\n",
    "    std = np.sqrt(np.mean(np.abs(ys - ys_pred) ** 2))\n",
    "    return std\n",
    "\n",
    "# 程序主入口（建议不要改动以下函数的接口）\n",
    "if __name__ == '__main__':\n",
    "    train_file = 'train.txt'\n",
    "    test_file = 'test.txt'\n",
    "    # 载入数据\n",
    "    x_train, y_train = load_data(train_file)\n",
    "    x_test, y_test = load_data(test_file)\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "\n",
    "    # 使用线性回归训练模型，返回一个函数f()使得y = f(x)\n",
    "    f = main(x_train, y_train)\n",
    "\n",
    "    y_train_pred = f(x_train)\n",
    "    std = evaluate(y_train, y_train_pred)\n",
    "    print('训练集预测值与真实值的标准差：{:.1f}'.format(std))\n",
    "    \n",
    "    # 计算预测的输出值\n",
    "    y_test_pred = f(x_test)\n",
    "    # 使用测试集评估模型\n",
    "    std = evaluate(y_test, y_test_pred)\n",
    "    print('预测值与真实值的标准差：{:.1f}'.format(std))\n",
    "\n",
    "    #显示结果\n",
    "    plt.plot(x_train, y_train, 'ro', markersize=3)\n",
    "    #plt.plot(x_test, y_test, 'k')\n",
    "    plt.plot(x_test, y_test_pred, 'k')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Linear Regression')\n",
    "    plt.legend(['train', 'test', 'pred'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "f3fc8f37d07408d45c02bd233883b3c0626fd53f17222167d698ff7ffd3f87d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
